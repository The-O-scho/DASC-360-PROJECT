pch=16, col="blue", xlab="Population Density (per kmÂ²)",
main="Population Density", vertical=FALSE)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
ggpairs(numeric_final, upper = list(continuous = wrap("cor", size = 3)))
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
# Correlation matrix visualization
pairs(numeric_final, pch=16, col=rgb(0,0,1,0.3))
corrplot(cor(numeric_final, use = "complete.obs"), method = "square", type = "upper")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
mahalanobis_distances = mahalanobis(numeric_final, colMeans(numeric_final), cov(numeric_final))
df = ncol(numeric_final)
cutoff_value = qchisq(1 - 0.05, df)
outliers = which(mahalanobis_distances > cutoff_value)
cat("Outlier indices:", outliers, "\n\n")
cat("Countries identified as outliers:\n")
final[outliers, ]
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
mean_vals = colMeans(numeric_final)
sd_vals = apply(numeric_final, 2, sd)
upper_bound = mean_vals + 2 * sd_vals
lower_bound = mean_vals - 2 * sd_vals
comparison = rbind(numeric_final[outliers, ], mean_vals, upper_bound, lower_bound)
comparison = as.data.frame(comparison)
rownames(comparison)[(length(outliers)+1):(length(outliers)+3)] = c("Mean", "Mean+2SD", "Mean-2SD")
round(comparison, 2)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
cor_with_outliers = cor(numeric_final)
cor_without_outliers = cor(numeric_final[-outliers, ])
cor_difference = cor_with_outliers - cor_without_outliers
cat("Correlation differences (with outliers - without outliers):\n")
round(cor_difference, 3)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
# Response variables
final_matrix_response = as.matrix(final[,c(3,5,9)])
R_response = cor(final_matrix_response)
eigen_response = eigen(R_response)
# Predictor variables
final_matrix_predictor = as.matrix(final[,-c(1,3,5,9)])
R_predictor = cor(final_matrix_predictor)
eigen_predictor = eigen(R_predictor)
# Scree plots
par(mfrow=c(1,2))
plot(eigen_response$values, type = "b", xlab = "Factor", ylab = "Eigenvalue",
main = "Scree Plot: Response Variables", pch=16, col="darkred")
abline(h=1, lty=2, col="blue")
abline(h=0.7, lty=2, col="green")
plot(eigen_predictor$values, type = "b", xlab = "Factor", ylab = "Eigenvalue",
main = "Scree Plot: Predictor Variables", pch=16, col="darkred")
abline(h=1, lty=2, col="blue")
abline(h=0.7, lty=2, col="green")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
cat("Response Variables:\n")
cat("Kaiser's criterion (eigenvalue > 1):", which(eigen_response$values > 1), "\n")
cat("Jolliffe's criterion (eigenvalue > 0.7):", which(eigen_response$values > 0.7), "\n\n")
cat("Predictor Variables:\n")
cat("Kaiser's criterion (eigenvalue > 1):", which(eigen_predictor$values > 1), "\n")
cat("Jolliffe's criterion (eigenvalue > 0.7):", which(eigen_predictor$values > 0.7), "\n")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
par(mfrow=c(1,2))
corrplot(R_response, method="color", order = "hclust",
title = "Response Variables", mar=c(0,0,2,0))
corrplot(R_predictor, method="color", order = "hclust",
title = "Predictor Variables", mar=c(0,0,2,0))
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
# Response variables
Response_Rotated_orthogonal_1 = pca(r = R_response, nfactors = 1, rotate = "varimax")$loadings[]
Response_Rotated_orthogonal_2 = pca(r = R_response, nfactors = 2, rotate = "varimax")$loadings[]
Response_Rotated_oblique_1 = pca(r = R_response, nfactors = 1, rotate = "oblimin")$loadings[]
Response_Rotated_oblique_2 = pca(r = R_response, nfactors = 2, rotate = "oblimin")$loadings[]
cat("Response Variables - Orthogonal Rotation (2 factors):\n")
print(round(Response_Rotated_orthogonal_2, 3))
Var_response_orth_1 = colSums(Response_Rotated_orthogonal_1^2/nrow(Response_Rotated_orthogonal_1))
Var_response_orth_2 = colSums(Response_Rotated_orthogonal_2^2/nrow(Response_Rotated_orthogonal_2))
cat("\nVariance explained (1 factor):", round(Var_response_orth_1, 3), "\n")
cat("Variance explained (2 factors):", round(Var_response_orth_2, 3), "\n")
cat("Total variance (2 factors):", round(sum(Var_response_orth_2), 3), "\n\n")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
# Predictor variables
Predictor_Rotated_orthogonal_1 = pca(r = R_predictor, nfactors = 1, rotate = "varimax")$loadings[]
Predictor_Rotated_orthogonal_3 = pca(r = R_predictor, nfactors = 3, rotate = "varimax")$loadings[]
Predictor_Rotated_oblique_1 = pca(r = R_predictor, nfactors = 1, rotate = "oblimin")$loadings[]
Predictor_Rotated_oblique_3 = pca(r = R_predictor, nfactors = 3, rotate = "oblimin")$loadings[]
cat("Predictor Variables - Orthogonal Rotation (3 factors):\n")
print(round(Predictor_Rotated_orthogonal_3, 3))
Var_predictor_orth_1 = colSums(Predictor_Rotated_orthogonal_1^2/nrow(Predictor_Rotated_orthogonal_1))
Var_predictor_orth_3 = colSums(Predictor_Rotated_orthogonal_3^2/nrow(Predictor_Rotated_orthogonal_3))
cat("\nVariance explained (1 factor):", round(Var_predictor_orth_1, 3), "\n")
cat("Variance explained (3 factors):", round(Var_predictor_orth_3, 3), "\n")
cat("Total variance (3 factors):", round(sum(Var_predictor_orth_3), 3), "\n")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
cat("=== RESPONSE VARIABLES (2 factors) ===\n")
print(round(Response_Rotated_orthogonal_2, 3))
cat("\nVariance explained by each factor:\n")
print(round(Var_response_orth_2, 3))
cat("Total variance retained:", round(sum(Var_response_orth_2), 3), "(",
round(100*sum(Var_response_orth_2), 1), "%)\n\n")
cat("=== PREDICTOR VARIABLES (3 factors) ===\n")
print(round(Predictor_Rotated_orthogonal_3, 3))
cat("\nVariance explained by each factor:\n")
print(round(Var_predictor_orth_3, 3))
cat("Total variance retained:", round(sum(Var_predictor_orth_3), 3), "(",
round(100*sum(Var_predictor_orth_3), 1), "%)\n")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
# Response variables
R_hat_response = Response_Rotated_orthogonal_2 %*% t(Response_Rotated_orthogonal_2)
A_resid_response = R_response - R_hat_response
cat("Response Variables - Correlation Residuals:\n")
print(round(A_resid_response, 4))
# Predictor variables
R_hat_predictor = Predictor_Rotated_orthogonal_3 %*% t(Predictor_Rotated_orthogonal_3)
A_resid_predictor = R_predictor - R_hat_predictor
cat("\n\nPredictor Variables - Correlation Residuals:\n")
print(round(A_resid_predictor, 4))
Predictor_Rotated_oblique_3
pca(r = R_predictor, nfactors = 3, rotate = "oblimin")
pca(r = R_response, nfactors = 2, rotate = "oblimin")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(jsonlite)
library(readxl)
library(psych)
library(ggplot2)
library(corrplot)
library(GGally)
# Load datasets from Our World in Data and other sources
df_1 = read.csv("https://ourworldindata.org/grapher/expected-years-of-schooling.csv?v=1&csvType=filtered&useColumnShortNames=true&mapSelect=CHN~NOR~SWE~FIN~CAN~USA~RUS~DEU~NLD~DNK~IRL~ISL~GBR~ESP~FRA~ITA~MEX~IND~BFA~MLI~DZA~TCD~ZAF~RWA~COD~PRY~BRA~PER~COL~AUS~NZL~PNG~PAK&overlay=download-data")
df_2 = read.csv("https://ourworldindata.org/grapher/average-years-of-schooling.csv?v=1&csvType=filtered&useColumnShortNames=true&mapSelect=CAN~USA~MEX~RUS~CHN~GBR~IRL~ISL~AND~ESP~FRA~DEU~DNK~NLD~ITA~BFA~RWA~COD~ZAF~SOM~TCD~DZA~MLI~AUS~PNG~NZL~BRA~PER~COL~NOR~FIN~SWE&overlay=download-data")
df_3 = read.csv("https://ourworldindata.org/grapher/total-government-expenditure-on-education-gdp.csv?v=1&csvType=filtered&useColumnShortNames=true&mapSelect=CAN~USA&overlay=download-data")
df_4 = read.csv("https://ourworldindata.org/grapher/schools-access-drinking-water.csv?v=1&csvType=full&useColumnShortNames=true")
df_5 = read.csv("https://ourworldindata.org/grapher/human-rights-index-vdem.csv?v=1&csvType=full&useColumnShortNames=true")
df_5 = df_5 %>%
group_by(Entity) %>%
mutate(mean_human_rights = mean(civ_libs_vdem__estimate_best, na.rm = TRUE))
df_6 = read.csv("world_population.csv")
df_6 = df_6 %>%
rename(Entity = Country.Territory)
df_6 = df_6[,c("Entity", "Density..per.km.." )]
df_7 = read_excel("publications.xlsx")
df_7 = df_7 %>%
rename(Entity = Country)
df_7 = df_7[,c("Entity","Citations per document")]
# Merge all datasets
df_8 = merge(df_1, df_2, all = TRUE)
df_9 = merge(df_3, df_4, all = TRUE)
df_10 = merge(df_5, df_6, all = TRUE)
df_11 = merge(df_7, df_8, all = TRUE)
df_12 = merge(df_9, df_10, all = TRUE)
df_13 = merge(df_11, df_12, all = TRUE)
# Aggregate by country and clean
final = df_13 %>%
group_by(Entity) %>%
summarise(across(everything(), ~ first(na.omit(.)))) %>%
drop_na() %>%
dplyr::select(-Code, -Year, -time.1, -time, -owid_region, -civ_libs_vdem__estimate_best)
# Rename variables for clarity
final = final %>%
rename(expected_schooling = eys__sex_total,
mean_schooling = mys__sex_total,
GDP_share = combined_expenditure_share_gdp,
primary_water = X_4_a_1__se_acs_h2o__primary,
upper_secondary_water = X_4_a_1__se_acs_h2o__upper_secondary,
lower_secondary_water = X_4_a_1__se_acs_h2o__lower_secondary,
mean_rights = mean_human_rights,
density_per_km = Density..per.km..)
head(final)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
numeric_final = final[,-c(1)]
describe(numeric_final)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
ggpairs(numeric_final, upper = list(continuous = wrap("cor", size = 3)))
knitr::include_graphics("PS Path.drawio.png")
library(lavaan)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(jsonlite)
library(readxl)
library(psych)
library(ggplot2)
library(corrplot)
library(GGally)
library(lavaan)
# Load datasets from Our World in Data and other sources
df_1 = read.csv("https://ourworldindata.org/grapher/expected-years-of-schooling.csv?v=1&csvType=filtered&useColumnShortNames=true&mapSelect=CHN~NOR~SWE~FIN~CAN~USA~RUS~DEU~NLD~DNK~IRL~ISL~GBR~ESP~FRA~ITA~MEX~IND~BFA~MLI~DZA~TCD~ZAF~RWA~COD~PRY~BRA~PER~COL~AUS~NZL~PNG~PAK&overlay=download-data")
df_2 = read.csv("https://ourworldindata.org/grapher/average-years-of-schooling.csv?v=1&csvType=filtered&useColumnShortNames=true&mapSelect=CAN~USA~MEX~RUS~CHN~GBR~IRL~ISL~AND~ESP~FRA~DEU~DNK~NLD~ITA~BFA~RWA~COD~ZAF~SOM~TCD~DZA~MLI~AUS~PNG~NZL~BRA~PER~COL~NOR~FIN~SWE&overlay=download-data")
df_3 = read.csv("https://ourworldindata.org/grapher/total-government-expenditure-on-education-gdp.csv?v=1&csvType=filtered&useColumnShortNames=true&mapSelect=CAN~USA&overlay=download-data")
df_4 = read.csv("https://ourworldindata.org/grapher/schools-access-drinking-water.csv?v=1&csvType=full&useColumnShortNames=true")
df_5 = read.csv("https://ourworldindata.org/grapher/human-rights-index-vdem.csv?v=1&csvType=full&useColumnShortNames=true")
df_5 = df_5 %>%
group_by(Entity) %>%
mutate(mean_human_rights = mean(civ_libs_vdem__estimate_best, na.rm = TRUE))
df_6 = read.csv("world_population.csv")
df_6 = df_6 %>%
rename(Entity = Country.Territory)
df_6 = df_6[,c("Entity", "Density..per.km.." )]
df_7 = read_excel("publications.xlsx")
df_7 = df_7 %>%
rename(Entity = Country)
df_7 = df_7[,c("Entity","Citations per document")]
# Merge all datasets
df_8 = merge(df_1, df_2, all = TRUE)
df_9 = merge(df_3, df_4, all = TRUE)
df_10 = merge(df_5, df_6, all = TRUE)
df_11 = merge(df_7, df_8, all = TRUE)
df_12 = merge(df_9, df_10, all = TRUE)
df_13 = merge(df_11, df_12, all = TRUE)
# Aggregate by country and clean
final = df_13 %>%
group_by(Entity) %>%
summarise(across(everything(), ~ first(na.omit(.)))) %>%
drop_na() %>%
dplyr::select(-Code, -Year, -time.1, -time, -owid_region, -civ_libs_vdem__estimate_best)
# Rename variables for clarity
final = final %>%
rename(expected_schooling = eys__sex_total,
mean_schooling = mys__sex_total,
GDP_share = combined_expenditure_share_gdp,
primary_water = X_4_a_1__se_acs_h2o__primary,
upper_secondary_water = X_4_a_1__se_acs_h2o__upper_secondary,
lower_secondary_water = X_4_a_1__se_acs_h2o__lower_secondary,
mean_rights = mean_human_rights,
density_per_km = Density..per.km..)
head(final)
MOD = sem(model = EQN, sample.cov = cor(numeric_final), sample.nobs = 95)
EQN = '
EQN = '
# Measurement Model (Factor Definition)
CitationPerDocument =~ Citationperdocument
HumanDevelopment =~ mean_rights + expected_schooling
Mean_Schooling_Water =~ primary_water + upper_secondary_water + lower_secondary_water + GDP_share
# Measurement Model (Covariances)
CitationPerDocument ~~ mean_schooling
Mean_Schooling_Water ~~ mean_schooling
# Structural Model
HumanDevelopment ~ population_density + CitationPerDocument + Mean_Schooling_Water
GDP_share ~ population_density + CitationPerDocument + Mean_Schooling_Water
EQN = '
# Measurement Model (Factor Definition)
CitationPerDocument =~ Citationperdocument
HumanDevelopment =~ mean_rights + expected_schooling
Mean_Schooling_Water =~ primary_water + upper_secondary_water + lower_secondary_water + GDP_share
# Measurement Model (Covariances)
CitationPerDocument ~~ mean_schooling
Mean_Schooling_Water ~~ mean_schooling
# Structural Model
HumanDevelopment ~ population_density + CitationPerDocument + Mean_Schooling_Water
GDP_share ~ population_density + CitationPerDocument + Mean_Schooling_Water
'
MOD = sem(model = EQN, sample.cov = cor(numeric_final), sample.nobs = 95)
numeric_final
MOD = sem(model = EQN, sample.cov = cor(numeric_final), sample.nobs = 95)
numeric_final
EQN = '
# Measurement Model (Factor Definition)
CitationPerDocument =~ `Citations per document`
HumanDevelopment =~ mean_rights + expected_schooling
Mean_Schooling_Water =~ primary_water + upper_secondary_water + lower_secondary_water + GDP_share
# Measurement Model (Covariances)
CitationPerDocument ~~ mean_schooling
Mean_Schooling_Water ~~ mean_schooling
# Structural Model
HumanDevelopment ~ density_per_km  + CitationPerDocument + Mean_Schooling_Water
GDP_share ~ density_per_km  + CitationPerDocument + Mean_Schooling_Water
'
MOD = sem(model = EQN, sample.cov = cor(numeric_final), sample.nobs = 95)
numeric_final = numeric_final %>%
rename(Citationperdocument = `Citations per document`)
numeric_final
EQN = '
# Measurement Model (Factor Definition)
CitationPerDocument =~ Citationperdocument
HumanDevelopment =~ mean_rights + expected_schooling
Mean_Schooling_Water =~ primary_water + upper_secondary_water + lower_secondary_water + GDP_share
# Measurement Model (Covariances)
CitationPerDocument ~~ mean_schooling
Mean_Schooling_Water ~~ mean_schooling
# Structural Model
HumanDevelopment ~ density_per_km  + CitationPerDocument + Mean_Schooling_Water
GDP_share ~ density_per_km  + CitationPerDocument + Mean_Schooling_Water
'
MOD = sem(model = EQN, sample.cov = cor(numeric_final), sample.nobs = 95)
MOD
numeric_final = numeric_final %>%
rename(Citationperdocument = `Citations per document`, population_density = density_per_km)
numeric_final = numeric_final %>%
rename(Citationperdocument = `Citations per document` + population_density = density_per_km)
numeric_final = numeric_final %>%
rename(Citationperdocument = `Citations per document`,
population_density = density_per_km)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(jsonlite)
library(readxl)
library(psych)
library(ggplot2)
library(corrplot)
library(GGally)
library(lavaan)
# Load datasets from Our World in Data and other sources
df_1 = read.csv("https://ourworldindata.org/grapher/expected-years-of-schooling.csv?v=1&csvType=filtered&useColumnShortNames=true&mapSelect=CHN~NOR~SWE~FIN~CAN~USA~RUS~DEU~NLD~DNK~IRL~ISL~GBR~ESP~FRA~ITA~MEX~IND~BFA~MLI~DZA~TCD~ZAF~RWA~COD~PRY~BRA~PER~COL~AUS~NZL~PNG~PAK&overlay=download-data")
df_2 = read.csv("https://ourworldindata.org/grapher/average-years-of-schooling.csv?v=1&csvType=filtered&useColumnShortNames=true&mapSelect=CAN~USA~MEX~RUS~CHN~GBR~IRL~ISL~AND~ESP~FRA~DEU~DNK~NLD~ITA~BFA~RWA~COD~ZAF~SOM~TCD~DZA~MLI~AUS~PNG~NZL~BRA~PER~COL~NOR~FIN~SWE&overlay=download-data")
df_3 = read.csv("https://ourworldindata.org/grapher/total-government-expenditure-on-education-gdp.csv?v=1&csvType=filtered&useColumnShortNames=true&mapSelect=CAN~USA&overlay=download-data")
df_4 = read.csv("https://ourworldindata.org/grapher/schools-access-drinking-water.csv?v=1&csvType=full&useColumnShortNames=true")
df_5 = read.csv("https://ourworldindata.org/grapher/human-rights-index-vdem.csv?v=1&csvType=full&useColumnShortNames=true")
df_5 = df_5 %>%
group_by(Entity) %>%
mutate(mean_human_rights = mean(civ_libs_vdem__estimate_best, na.rm = TRUE))
df_6 = read.csv("world_population.csv")
df_6 = df_6 %>%
rename(Entity = Country.Territory)
df_6 = df_6[,c("Entity", "Density..per.km.." )]
df_7 = read_excel("publications.xlsx")
df_7 = df_7 %>%
rename(Entity = Country)
df_7 = df_7[,c("Entity","Citations per document")]
# Merge all datasets
df_8 = merge(df_1, df_2, all = TRUE)
df_9 = merge(df_3, df_4, all = TRUE)
df_10 = merge(df_5, df_6, all = TRUE)
df_11 = merge(df_7, df_8, all = TRUE)
df_12 = merge(df_9, df_10, all = TRUE)
df_13 = merge(df_11, df_12, all = TRUE)
# Aggregate by country and clean
final = df_13 %>%
group_by(Entity) %>%
summarise(across(everything(), ~ first(na.omit(.)))) %>%
drop_na() %>%
dplyr::select(-Code, -Year, -time.1, -time, -owid_region, -civ_libs_vdem__estimate_best)
# Rename variables for clarity
final = final %>%
rename(expected_schooling = eys__sex_total,
mean_schooling = mys__sex_total,
GDP_share = combined_expenditure_share_gdp,
primary_water = X_4_a_1__se_acs_h2o__primary,
upper_secondary_water = X_4_a_1__se_acs_h2o__upper_secondary,
lower_secondary_water = X_4_a_1__se_acs_h2o__lower_secondary,
mean_rights = mean_human_rights,
density_per_km = Density..per.km..)
head(final)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
numeric_final = final[,-c(1)]
describe(numeric_final)
numeric_final = numeric_final %>%
rename(Citationperdocument = `Citations per document`,
population_density = density_per_km)
numeric_final = numeric_final %>%
rename(Citationperdocument = `Citations per document`,
population_density = density_per_km)
EQN = '
# Measurement Model (Factor Definition)
CitationPerDocument =~ Citationperdocument
HumanDevelopment =~ mean_rights + expected_schooling
Mean_Schooling_Water =~ primary_water + upper_secondary_water + lower_secondary_water + GDP_share
# Measurement Model (Covariances)
CitationPerDocument ~~ mean_schooling
Mean_Schooling_Water ~~ mean_schooling
# Structural Model
HumanDevelopment ~ population_density  + CitationPerDocument + Mean_Schooling_Water
GDP_share ~ population_density  + CitationPerDocument + Mean_Schooling_Water
'
MOD = sem(model = EQN, sample.cov = cor(numeric_final), sample.nobs = 95)
MOD
EQN = '
# Measurement Model (Factor Definition)
CitationPerDocument =~ Citationperdocument
HumanDevelopment =~ mean_rights + expected_schooling
Mean_Schooling_Water =~ primary_water + upper_secondary_water + lower_secondary_water
# Measurement Model (Covariances)
CitationPerDocument ~~ mean_schooling
Mean_Schooling_Water ~~ mean_schooling
# Structural Model
HumanDevelopment ~ population_density  + CitationPerDocument + Mean_Schooling_Water
GDP_share ~ population_density  + CitationPerDocument + Mean_Schooling_Water
'
MOD = sem(model = EQN, sample.cov = cor(numeric_final), sample.nobs = 95)
MOD
params = parameterEstimates(MOD)
params
MOD$df
MOD
MOD$`Degrees of freedom`
MOD
params
numeric_final
EQN = '
# Measurement Model (Factor Definition)
Citationperdocument =~ Citationperdocument
HumanDevelopment =~ mean_rights + expected_schooling
Mean_Schooling_Water =~ primary_water + upper_secondary_water + lower_secondary_water
# Measurement Model (Covariances)
CitationPerDocument ~~ mean_schooling
Mean_Schooling_Water ~~ mean_schooling
# Structural Model
HumanDevelopment ~ population_density  + Citationperdocument + Mean_Schooling_Water
GDP_share ~ population_density  + Citationperdocument + Mean_Schooling_Water
'
MOD = sem(model = EQN, sample.cov = cor(numeric_final), sample.nobs = 95)
EQN = '
# Measurement Model (Factor Definition)
CitationPerDocument =~ Citationperdocument
HumanDevelopment =~ mean_rights + expected_schooling
Mean_Schooling_Water =~ primary_water + upper_secondary_water + lower_secondary_water
# Measurement Model (Covariances)
CitationPerDocument ~~ mean_schooling
Mean_Schooling_Water ~~ mean_schooling
# Structural Model
HumanDevelopment ~ population_density  + CitationPerDocument + Mean_Schooling_Water
GDP_share ~ population_density  + CitationPerDocument + Mean_Schooling_Water
'
MOD = sem(model = EQN, sample.cov = cor(numeric_final), sample.nobs = 95)
MOD
degrees_of_freedom(MOD)
install.packages("parameters")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(jsonlite)
library(readxl)
library(psych)
library(ggplot2)
library(corrplot)
library(GGally)
library(lavaan)
library(parameters)
# Load datasets from Our World in Data and other sources
df_1 = read.csv("https://ourworldindata.org/grapher/expected-years-of-schooling.csv?v=1&csvType=filtered&useColumnShortNames=true&mapSelect=CHN~NOR~SWE~FIN~CAN~USA~RUS~DEU~NLD~DNK~IRL~ISL~GBR~ESP~FRA~ITA~MEX~IND~BFA~MLI~DZA~TCD~ZAF~RWA~COD~PRY~BRA~PER~COL~AUS~NZL~PNG~PAK&overlay=download-data")
df_2 = read.csv("https://ourworldindata.org/grapher/average-years-of-schooling.csv?v=1&csvType=filtered&useColumnShortNames=true&mapSelect=CAN~USA~MEX~RUS~CHN~GBR~IRL~ISL~AND~ESP~FRA~DEU~DNK~NLD~ITA~BFA~RWA~COD~ZAF~SOM~TCD~DZA~MLI~AUS~PNG~NZL~BRA~PER~COL~NOR~FIN~SWE&overlay=download-data")
df_3 = read.csv("https://ourworldindata.org/grapher/total-government-expenditure-on-education-gdp.csv?v=1&csvType=filtered&useColumnShortNames=true&mapSelect=CAN~USA&overlay=download-data")
df_4 = read.csv("https://ourworldindata.org/grapher/schools-access-drinking-water.csv?v=1&csvType=full&useColumnShortNames=true")
df_5 = read.csv("https://ourworldindata.org/grapher/human-rights-index-vdem.csv?v=1&csvType=full&useColumnShortNames=true")
df_5 = df_5 %>%
group_by(Entity) %>%
mutate(mean_human_rights = mean(civ_libs_vdem__estimate_best, na.rm = TRUE))
df_6 = read.csv("world_population.csv")
df_6 = df_6 %>%
rename(Entity = Country.Territory)
df_6 = df_6[,c("Entity", "Density..per.km.." )]
df_7 = read_excel("publications.xlsx")
df_7 = df_7 %>%
rename(Entity = Country)
df_7 = df_7[,c("Entity","Citations per document")]
# Merge all datasets
df_8 = merge(df_1, df_2, all = TRUE)
df_9 = merge(df_3, df_4, all = TRUE)
df_10 = merge(df_5, df_6, all = TRUE)
df_11 = merge(df_7, df_8, all = TRUE)
df_12 = merge(df_9, df_10, all = TRUE)
df_13 = merge(df_11, df_12, all = TRUE)
# Aggregate by country and clean
final = df_13 %>%
group_by(Entity) %>%
summarise(across(everything(), ~ first(na.omit(.)))) %>%
drop_na() %>%
dplyr::select(-Code, -Year, -time.1, -time, -owid_region, -civ_libs_vdem__estimate_best)
# Rename variables for clarity
final = final %>%
rename(expected_schooling = eys__sex_total,
mean_schooling = mys__sex_total,
GDP_share = combined_expenditure_share_gdp,
primary_water = X_4_a_1__se_acs_h2o__primary,
upper_secondary_water = X_4_a_1__se_acs_h2o__upper_secondary,
lower_secondary_water = X_4_a_1__se_acs_h2o__lower_secondary,
mean_rights = mean_human_rights,
density_per_km = Density..per.km..)
head(final)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
numeric_final = final[,-c(1)]
describe(numeric_final)
numeric_final = numeric_final %>%
rename(Citationperdocument = `Citations per document`,
population_density = density_per_km)
EQN = '
# Measurement Model (Factor Definition)
CitationPerDocument =~ Citationperdocument
HumanDevelopment =~ mean_rights + expected_schooling
Mean_Schooling_Water =~ primary_water + upper_secondary_water + lower_secondary_water
# Measurement Model (Covariances)
CitationPerDocument ~~ mean_schooling
Mean_Schooling_Water ~~ mean_schooling
# Structural Model
HumanDevelopment ~ population_density  + CitationPerDocument + Mean_Schooling_Water
GDP_share ~ population_density  + CitationPerDocument + Mean_Schooling_Water
'
MOD = sem(model = EQN, sample.cov = cor(numeric_final), sample.nobs = 95)
MOD
degrees_of_freedom(MOD)
fitMeasures(MOD, "df")
params
params = parameterEstimates(MOD)
params
high_z = params %>%
filter(abs(z) > 1.96) %>%
arrange(desc(abs(z)))
high_z
print(lhs,op,rhs)
params = parameterEstimates(MOD)
params
high_z = params %>%
filter(abs(z) > 1.96) %>%
arrange(desc(abs(z)))
lhs = high_z$lhs
op = high_z$op
rhs = high_z$rhs
print(lhs,op,rhs)
print(lhs,op,rhs)
high_z
high_z %>%
select(lhs, op, rhs)
